{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 03: Regresión Polinomial y Regresión Logística\n",
    "\n",
    "El objetivo de esta actividad es que:\n",
    "\n",
    "- Entiendas el modelo de regresión polinomial.\n",
    "- Programes tu mismo un modelo de regresión logística. Luego, debes probar tu modelo con el _dataset_ de flores _Iris_.\n",
    "\n",
    "## Parte 1 (1.5 pts) - Regresión Polinomial\n",
    "\n",
    "Considera una secuencia de puntos en el plano $(x_1,\\ y_1),\\ (x_2,\\ y_2),\\ \\dots,\\ (x_n,\\ y_n)$ que tú consideras que distribuyen según un polinomio de grado $k$. Para ajustar un polinomio de grado $k$:\n",
    "\n",
    "$$\n",
    "\\hat{y}(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\dots + \\beta_k x^k\n",
    "$$\n",
    "\n",
    "para estos datos, lo que se hace es entrenar un modelo de **regresión lineal multivariable** en donde el _dataset_ de entrada sería:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(1,\\ x_1,\\ x_1^2,\\ \\dots,\\ x_1^k) \\nonumber \\\\\n",
    "(1,\\ x_2,\\ x_2^2,\\ \\dots,\\ x_2^k) \\nonumber \\\\ \n",
    "\\dots \\nonumber \\\\\n",
    "(1,\\ x_n,\\ x_n^2,\\ \\dots,\\ x_n^k) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**\\[1.5 pts\\]** Demuestra que al usar el algoritmo de regresión lineal multivariable sobre el _dataset_ de entrada mencionado, estamos aprendiendo el polinomio de grado $k$ que pasa lo más cerca posible de los datos.\n",
    "\n",
    "**Hint**: piensa en cómo se ve el problema de optimización de mínimos cuadrados cuando queremos ajustar una regresión lineal de $k$ variables. También considera que en ambos casos estás aprendiendo los coeficientes $\\beta_0,\\ \\beta_1,\\ \\beta_2,\\ \\dots,\\ \\beta_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contesta tu pregunta en esta celda**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 (5.5 pts) - Regresión Logística\n",
    "\n",
    "### Parte 2.1 (2.5 pts): programando el modelo\n",
    "\n",
    "En el codigo de abajo hay una clase llamada `LogisticRegression` cuyo constructor recibe como parámetro el número de _features_ que espera recibir. Tienes que completar esta clase para que pueda entrenar y predecir. Lo que necesitas es:\n",
    "\n",
    "- Programar el método `train`, que vendría a ser equivalente al método `fit` de Scikit Learn. Tienes que utilizar el algoritmo _Gradient Descent_ visto en clases.\n",
    "- Programar el método `predict` que asume que tu modelo ya está entrenado.\n",
    "\n",
    "Para hacer esto puedes hacer los supuestos razonables que estimes conveniente. Además, si te acomoda trabajar sin clases puedes hacerlo, mientras uses el algoritmo de _Gradient Descent_. **Importante**: puedes asumir que una instancia es \"positiva\" si la probabilidad es `>=` que 0.5.\n",
    "\n",
    "Recuerda además que el gradiente de la función objetivo para cada $\\beta_i$ es:\n",
    "\n",
    "$$\n",
    "\\frac{\\delta}{\\delta \\beta_i}L(\\beta) = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(\\beta^T x_i) - y_i) x_i^j\n",
    "$$\n",
    "\n",
    "Donde $L(\\beta)$ es la función objetivo, $\\beta$ es el vector de coeficientes para la regresión, tenemos $n$ filas en nuestro _dataset_, $\\sigma(x)$ es la función $\\frac{1}{1 + e^{-x}}$, $x_i$ es la fila $i$ de nuestro dataset (y asociado tiene su respuesta $y_i$) y finalmente $x_i^j$ es la columna $j$ de la fila $i$ en nuestro _dataset_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tienes que programar la parte 1 aquí\n",
    "import numpy as np\n",
    "\n",
    "# La función sigmoide\n",
    "def sigmoid(x):    \n",
    "    output = 1 / (1 + np.exp(-x))\n",
    "    return output\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, number_of_features, learning_rate=0.001, number_of_iterations=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.number_of_iterations = number_of_iterations\n",
    "        self.beta = np.random.randn(number_of_features, 1)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # Tienes que programar este método\n",
    "        pass\n",
    "    \n",
    "    def predict(self, value):\n",
    "        # Tienes que programar este método\n",
    "        pass\n",
    "\n",
    "# Ejemplo de uso de la clase para 3 features\n",
    "log_reg = LogisticRegression(3)\n",
    "print(log_reg.beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2.2 (1 pto) -  Entrenando el Modelo\n",
    "\n",
    "En esta parte tendrás que hacer un clasificador de flores _Iris Virginica_ en base al largo y ancho del pétalo. Así, tu modelo se tiene que comportar como el que vimos en clases, en el que entrenabamos con los largos y anchos de los pétalos del _dataset_ y nuestras respuestas correspondían a si la flor era o no _Iris Virginica_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data'][:, (2,3)] # Nos quedamos solamente con el ancho del pétalo\n",
    "y = (iris['target'] == 2).astype(np.int) # Dejamos True en las filas que son Virginica\n",
    "\n",
    "# Recuerda que vas a tener que usar la versión con bias del dataset\n",
    "# Es decir, añadir una primera columna solamente con 1s\n",
    "X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "# Ahora un ejemplo de como multiplicar la fila 0 con los coeficientes transpuestos (descomentar linea siguiente)\n",
    "# log_reg.beta.T.dot(X_b[0,:].reshape(3,1))\n",
    "\n",
    "\n",
    "# Entrena el modelo acá, debería ser como la siguiente línea\n",
    "# log_reg.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2.3 (1 pto) - Entendiendo los Resultados de tu Modelo\n",
    "\n",
    "En clases vimos un gráfico que en los ejes tenía el largo y el ancho del pétalo, donde podíamos ver de forma gráfica como nuestro modelo genera una recta que divide los puntos que corresponden a las flores _Iris Virginica_ de las que no lo son. En esta parte de la tarea debes hacer el mismo gráfico, pero con los resultados que entregó tu modelo. Compara este gráfico con el entregado por SciKit Learn. ¿Qué tanto se asemeja tu modelo con el de `scikit-learn`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Evalúa tu modelo acá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4 \\[Bonus\\] (0.5 pts) - Gradient Descent y Resultados\n",
    "\n",
    "En esta parte la idea es entender cómo cambia la división de nuestro _dataset_ a medida que pasan las iteraciones del algoritmo de _Gradient Descent_. Por lo mismo la idea es repetir el gráfico de arriba pero esta vez con un _widget_ que nos permita escoger la i-ésima iteración del algoritmo de _Gradient Descent_. El _widget_ debe ir desde 0 a 1000 iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza el bonus acá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detalles académicos\n",
    "\n",
    "Esta actividad es individual. La entrega de este control debe ser mediante webcursos, y el formato es un archivo comprimido donde se encuentre un **Jupyter Notebook**, junto a cualquier archivo que estés llamando desde tu código y cualquier anexo que menciones. **La fecha de entrega es hasta el jueves 7 de octubre, hasta las 20:00 pm**. La nota se calcula como el número de puntos + un punto base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
